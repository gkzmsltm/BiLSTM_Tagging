{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "intelligent-civilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "from torchcrf import CRF\n",
    "from utils import batchify, evaluate_ner_F1, evaluate_ner_F1_and_write_result\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ahead-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, vocabs, word_dim, pos_dim, hidden_size, rnn_layers, dropout_rate,\n",
    "                 bidirectional=True, use_crf=False, embedding=None):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        word2id, tag2id, label2id = vocabs\n",
    "        self.word_embeddings = nn.Embedding(len(word2id), word_dim)\n",
    "        if embedding is not None:\n",
    "            self.word_embeddings.weight.data.copy_(torch.from_numpy(embedding))\n",
    "\n",
    "        self.tag_embeddings = nn.Embedding(len(tag2id), pos_dim)\n",
    "\n",
    "        self.lstm = nn.LSTM(word_dim + pos_dim, hidden_size, rnn_layers,\n",
    "                            batch_first=True, bidirectional=bidirectional, dropout=dropout_rate)\n",
    "\n",
    "        output_size = hidden_size * 2 if bidirectional else hidden_size\n",
    "\n",
    "        self.linear = nn.Linear(output_size, len(label2id))\n",
    "\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.use_crf = use_crf\n",
    "        if use_crf:\n",
    "            self.crf = CRF(len(label2id), batch_first=True)\n",
    "\n",
    "        self.cross_entropy = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    def forward(self, word_ids, tag_ids, label_ids):\n",
    "        word_emb = self.word_embeddings(word_ids)\n",
    "        tag_emb = self.tag_embeddings(tag_ids)\n",
    "\n",
    "        rnn_input = torch.cat([word_emb, tag_emb], dim=-1)\n",
    "\n",
    "        rnn_input = F.dropout(rnn_input, self.dropout_rate, self.training)\n",
    "\n",
    "        rnn_outputs, (hn, cn) = self.lstm(rnn_input)\n",
    "\n",
    "        logits = self.linear(rnn_outputs)\n",
    "\n",
    "        # [1, 1, 1, 0, 0]\n",
    "        # [1, 1, 1, 1, 1]\n",
    "        mask = word_ids.ne(0)\n",
    "        if self.training:  # training\n",
    "            if self.use_crf:\n",
    "                loss = -self.crf(logits, label_ids, mask=mask.byte())\n",
    "                return loss\n",
    "\n",
    "            else:\n",
    "                batch, seq_len, num_label = logits.size()\n",
    "\n",
    "                logits = logits.view(-1, logits.data.shape[-1])\n",
    "                label_ids = label_ids.view(-1)\n",
    "\n",
    "                loss = F.cross_entropy(logits, label_ids, reduction='none')\n",
    "                loss = loss.view(batch, seq_len)\n",
    "\n",
    "                loss = loss * mask.float()\n",
    "\n",
    "                num_tokens = mask.sum(1).sum(0)\n",
    "\n",
    "                loss = loss.sum(1).sum(0) / num_tokens\n",
    "                return loss\n",
    "\n",
    "        label_ids = label_ids.data.cpu().numpy().tolist()\n",
    "        lengths = mask.sum(1).long().tolist()\n",
    "\n",
    "        answers = []\n",
    "        for answer, length in zip(label_ids, lengths):\n",
    "            answers.append(answer[:length])\n",
    "\n",
    "        if self.use_crf:\n",
    "            predictions = self.crf.decode(logits, mask)\n",
    "\n",
    "            return answers, predictions\n",
    "\n",
    "        batch_preds = torch.argmax(logits, dim=-1)\n",
    "        batch_preds = batch_preds.data.cpu().numpy().tolist()\n",
    "\n",
    "        predictions = []\n",
    "        for pred, length in zip(batch_preds, lengths):\n",
    "            predictions.append(pred[:length])\n",
    "\n",
    "        return answers, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "impossible-assumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs=30, batch_size=32,\n",
    "          word_dim=100, pos_dim=50, hidden_size=300, rnn_layers=1, bidirectional=False,\n",
    "          use_pretrained=False, dropout_rate=0.0, use_crf=False, evaluate=False):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    with open(\"data.pkl\", \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    train, dev, test = data['train'], data['dev'], data['test']\n",
    "    word2id, tag2id, label2id, embedding = data['w2id'], data['t2id'], data['l2id'], data['embedding']\n",
    "\n",
    "    id2label = {i: l for l, i in label2id.items()}\n",
    "    model = Model((word2id, tag2id, label2id),\n",
    "                  word_dim=word_dim, pos_dim=pos_dim, hidden_size=hidden_size, rnn_layers=rnn_layers,\n",
    "                  dropout_rate=dropout_rate, bidirectional=bidirectional,\n",
    "                  embedding=embedding if use_pretrained else None, use_crf=use_crf)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    parameters = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "    optimizer = optim.Adam(parameters)\n",
    "\n",
    "    if evaluate:\n",
    "        state_dict = torch.load(os.path.join(\"save\", \"best_model.pt\"))\n",
    "        model.load_state_dict(state_dict)\n",
    "        print(\"Load Best Model in %s\" % os.path.join(\"save\", \"best_model.pt\"))\n",
    "\n",
    "        model_eval(model, dev, test, device, id2label)\n",
    "        exit()\n",
    "\n",
    "    best_F1 = 0.0\n",
    "    losses = []\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(\"Epoch %3d.....\" % epoch)\n",
    "        num_data = len(train)\n",
    "        num_batch = (num_data + batch_size - 1) // batch_size\n",
    "\n",
    "        model.train()\n",
    "        print(\"Start Training in Epoch %3d\" % epoch)\n",
    "        for ii in range(num_batch):\n",
    "\n",
    "            batch_word_ids, batch_tag_ids, batch_labels_ids = batchify(ii, batch_size, num_data, train)\n",
    "\n",
    "            batch_word_ids = batch_word_ids.to(device)\n",
    "            batch_tag_ids = batch_tag_ids.to(device)\n",
    "            batch_labels_ids = batch_labels_ids.to(device)\n",
    "\n",
    "            loss = model(batch_word_ids, batch_tag_ids, batch_labels_ids)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(loss.data)\n",
    "\n",
    "            if (ii + 1) % 100 == 0:\n",
    "                print(\"%6d/%6d: loss %.6f\" % (ii + 1, num_batch, sum(losses) / len(losses)))\n",
    "                losses = []\n",
    "\n",
    "        # Dev Evaluation\n",
    "        num_data = len(dev)\n",
    "        num_batch = (num_data + batch_size - 1) // batch_size\n",
    "\n",
    "        model.eval()\n",
    "        print(\"Dev Evaluation in Epoch %3d\" % epoch)\n",
    "\n",
    "        total_answer_ids, total_pred_ids = [], []\n",
    "        for ii in range(num_batch):\n",
    "            batch_word_ids, batch_tag_ids, batch_labels_ids = batchify(ii, batch_size, num_data, dev)\n",
    "\n",
    "            batch_word_ids = batch_word_ids.to(device)\n",
    "            batch_tag_ids = batch_tag_ids.to(device)\n",
    "            batch_labels_ids = batch_labels_ids.to(device)\n",
    "\n",
    "            batch_answer_ids, batch_pred_ids = model(batch_word_ids, batch_tag_ids, batch_labels_ids)\n",
    "\n",
    "            total_answer_ids.extend(batch_answer_ids)\n",
    "            total_pred_ids.extend(batch_pred_ids)\n",
    "\n",
    "        precision, recall, F1 = evaluate_ner_F1(total_answer_ids, total_pred_ids, id2label)\n",
    "\n",
    "        print(\"[Epoch %d][ Dev] precision : %.2f, recall : %.2f, F1 : %.2f\" % (epoch, precision, recall, F1))\n",
    "\n",
    "        if F1 > best_F1:\n",
    "            torch.save(model.state_dict(), os.path.join(\"save\", \"best_model.pt\"))\n",
    "            best_F1 = F1\n",
    "            print('[new best model saved.]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "endless-december",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(model, dev, test, device, id2label):\n",
    "    # Dev Evaluation\n",
    "    num_data = len(dev)\n",
    "    num_batch = (num_data + batch_size - 1) // batch_size\n",
    "\n",
    "    model.eval()\n",
    "    print(\"Dev Evaluation in Best Model\")\n",
    "\n",
    "    total_answer_ids, total_pred_ids = [], []\n",
    "    total_words = [sent[3] for sent in dev]\n",
    "    for ii in range(num_batch):\n",
    "        batch_word_ids, batch_tag_ids, batch_labels_ids = batchify(ii, batch_size, num_data, dev)\n",
    "\n",
    "        batch_word_ids = batch_word_ids.to(device)\n",
    "        batch_tag_ids = batch_tag_ids.to(device)\n",
    "        batch_labels_ids = batch_labels_ids.to(device)\n",
    "\n",
    "        batch_answer_ids, batch_pred_ids = model(batch_word_ids, batch_tag_ids, batch_labels_ids)\n",
    "\n",
    "        total_answer_ids.extend(batch_answer_ids)\n",
    "        total_pred_ids.extend(batch_pred_ids)\n",
    "\n",
    "    precision, recall, F1 = evaluate_ner_F1_and_write_result(total_words, total_answer_ids, total_pred_ids, id2label, setname='dev')\n",
    "\n",
    "    print(\"[Best][ Dev] precision : %.2f, recall : %.2f, F1 : %.2f\" % (precision, recall, F1))\n",
    "\n",
    "    # Test Evaluation\n",
    "    num_data = len(test)\n",
    "    num_batch = (num_data + batch_size - 1) // batch_size\n",
    "\n",
    "    model.eval()\n",
    "    print(\"Test Evaluation in Best Model\")\n",
    "\n",
    "    total_answer_ids, total_pred_ids = [], []\n",
    "    total_words = [sent[3] for sent in test]\n",
    "    for ii in range(num_batch):\n",
    "        batch_word_ids, batch_tag_ids, batch_labels_ids = batchify(ii, batch_size, num_data, test)\n",
    "\n",
    "        batch_word_ids = batch_word_ids.to(device)\n",
    "        batch_tag_ids = batch_tag_ids.to(device)\n",
    "        batch_labels_ids = batch_labels_ids.to(device)\n",
    "\n",
    "        batch_answer_ids, batch_pred_ids = model(batch_word_ids, batch_tag_ids, batch_labels_ids)\n",
    "\n",
    "        total_answer_ids.extend(batch_answer_ids)\n",
    "        total_pred_ids.extend(batch_pred_ids)\n",
    "\n",
    "    precision, recall, F1 = evaluate_ner_F1_and_write_result(total_words, total_answer_ids, total_pred_ids, id2label, setname='test')\n",
    "\n",
    "    print(\"[Best][Test] precision : %.2f, recall : %.2f, F1 : %.2f\" % (precision, recall, F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "prescribed-former",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "batch_size = 64\n",
    "epochs = 60\n",
    "word_dim = 100\n",
    "pos_dim = 50\n",
    "hidden_size = 256\n",
    "rnn_layers = 2\n",
    "dropout_rate = 0.33\n",
    "bidirectional = True\n",
    "use_pretrained = False\n",
    "use_crf = False\n",
    "evaluate = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "higher-wells",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1.....\n",
      "Start Training in Epoch   1\n",
      "   100/   235: loss 0.738576\n",
      "   200/   235: loss 0.355525\n",
      "Dev Evaluation in Epoch   1\n",
      "[Epoch 1][ Dev] precision : 40.18, recall : 42.36, F1 : 41.24\n",
      "[new best model saved.]\n",
      "Epoch   2.....\n",
      "Start Training in Epoch   2\n",
      "   100/   235: loss 0.298506\n",
      "   200/   235: loss 0.247008\n",
      "Dev Evaluation in Epoch   2\n",
      "[Epoch 2][ Dev] precision : 59.83, recall : 59.96, F1 : 59.90\n",
      "[new best model saved.]\n",
      "Epoch   3.....\n",
      "Start Training in Epoch   3\n",
      "   100/   235: loss 0.199795\n",
      "   200/   235: loss 0.189797\n",
      "Dev Evaluation in Epoch   3\n",
      "[Epoch 3][ Dev] precision : 67.29, recall : 67.27, F1 : 67.28\n",
      "[new best model saved.]\n",
      "Epoch   4.....\n",
      "Start Training in Epoch   4\n",
      "   100/   235: loss 0.148818\n",
      "   200/   235: loss 0.154544\n",
      "Dev Evaluation in Epoch   4\n",
      "[Epoch 4][ Dev] precision : 71.73, recall : 71.15, F1 : 71.44\n",
      "[new best model saved.]\n",
      "Epoch   5.....\n",
      "Start Training in Epoch   5\n",
      "   100/   235: loss 0.116400\n",
      "   200/   235: loss 0.126684\n",
      "Dev Evaluation in Epoch   5\n",
      "[Epoch 5][ Dev] precision : 73.32, recall : 73.12, F1 : 73.22\n",
      "[new best model saved.]\n",
      "Epoch   6.....\n",
      "Start Training in Epoch   6\n",
      "   100/   235: loss 0.092593\n",
      "   200/   235: loss 0.103616\n",
      "Dev Evaluation in Epoch   6\n",
      "[Epoch 6][ Dev] precision : 76.68, recall : 76.24, F1 : 76.46\n",
      "[new best model saved.]\n",
      "Epoch   7.....\n",
      "Start Training in Epoch   7\n",
      "   100/   235: loss 0.074974\n",
      "   200/   235: loss 0.084336\n",
      "Dev Evaluation in Epoch   7\n",
      "[Epoch 7][ Dev] precision : 78.26, recall : 77.85, F1 : 78.06\n",
      "[new best model saved.]\n",
      "Epoch   8.....\n",
      "Start Training in Epoch   8\n",
      "   100/   235: loss 0.059029\n",
      "   200/   235: loss 0.067516\n",
      "Dev Evaluation in Epoch   8\n",
      "[Epoch 8][ Dev] precision : 80.14, recall : 79.50, F1 : 79.82\n",
      "[new best model saved.]\n",
      "Epoch   9.....\n",
      "Start Training in Epoch   9\n",
      "   100/   235: loss 0.048738\n",
      "   200/   235: loss 0.054751\n",
      "Dev Evaluation in Epoch   9\n",
      "[Epoch 9][ Dev] precision : 80.21, recall : 79.69, F1 : 79.95\n",
      "[new best model saved.]\n",
      "Epoch  10.....\n",
      "Start Training in Epoch  10\n",
      "   100/   235: loss 0.041758\n",
      "   200/   235: loss 0.045641\n",
      "Dev Evaluation in Epoch  10\n",
      "[Epoch 10][ Dev] precision : 80.67, recall : 81.32, F1 : 80.99\n",
      "[new best model saved.]\n",
      "Epoch  11.....\n",
      "Start Training in Epoch  11\n",
      "   100/   235: loss 0.033692\n",
      "   200/   235: loss 0.039439\n",
      "Dev Evaluation in Epoch  11\n",
      "[Epoch 11][ Dev] precision : 82.28, recall : 82.11, F1 : 82.19\n",
      "[new best model saved.]\n",
      "Epoch  12.....\n",
      "Start Training in Epoch  12\n",
      "   100/   235: loss 0.028246\n",
      "   200/   235: loss 0.033421\n",
      "Dev Evaluation in Epoch  12\n",
      "[Epoch 12][ Dev] precision : 81.90, recall : 81.72, F1 : 81.81\n",
      "Epoch  13.....\n",
      "Start Training in Epoch  13\n",
      "   100/   235: loss 0.023961\n",
      "   200/   235: loss 0.027469\n",
      "Dev Evaluation in Epoch  13\n",
      "[Epoch 13][ Dev] precision : 82.20, recall : 81.67, F1 : 81.93\n",
      "Epoch  14.....\n",
      "Start Training in Epoch  14\n",
      "   100/   235: loss 0.019627\n",
      "   200/   235: loss 0.024568\n",
      "Dev Evaluation in Epoch  14\n",
      "[Epoch 14][ Dev] precision : 81.71, recall : 81.94, F1 : 81.83\n",
      "Epoch  15.....\n",
      "Start Training in Epoch  15\n",
      "   100/   235: loss 0.019356\n",
      "   200/   235: loss 0.021515\n",
      "Dev Evaluation in Epoch  15\n",
      "[Epoch 15][ Dev] precision : 81.83, recall : 81.61, F1 : 81.72\n",
      "Epoch  16.....\n",
      "Start Training in Epoch  16\n",
      "   100/   235: loss 0.017085\n",
      "   200/   235: loss 0.018686\n",
      "Dev Evaluation in Epoch  16\n",
      "[Epoch 16][ Dev] precision : 82.18, recall : 82.48, F1 : 82.33\n",
      "[new best model saved.]\n",
      "Epoch  17.....\n",
      "Start Training in Epoch  17\n",
      "   100/   235: loss 0.013915\n",
      "   200/   235: loss 0.016737\n",
      "Dev Evaluation in Epoch  17\n",
      "[Epoch 17][ Dev] precision : 82.48, recall : 82.48, F1 : 82.48\n",
      "[new best model saved.]\n",
      "Epoch  18.....\n",
      "Start Training in Epoch  18\n",
      "   100/   235: loss 0.012752\n",
      "   200/   235: loss 0.014260\n",
      "Dev Evaluation in Epoch  18\n",
      "[Epoch 18][ Dev] precision : 82.11, recall : 82.11, F1 : 82.11\n",
      "Epoch  19.....\n",
      "Start Training in Epoch  19\n",
      "   100/   235: loss 0.011814\n",
      "   200/   235: loss 0.013421\n",
      "Dev Evaluation in Epoch  19\n",
      "[Epoch 19][ Dev] precision : 82.08, recall : 82.08, F1 : 82.08\n",
      "Epoch  20.....\n",
      "Start Training in Epoch  20\n",
      "   100/   235: loss 0.011443\n",
      "   200/   235: loss 0.011924\n",
      "Dev Evaluation in Epoch  20\n",
      "[Epoch 20][ Dev] precision : 82.38, recall : 82.01, F1 : 82.20\n",
      "Epoch  21.....\n",
      "Start Training in Epoch  21\n",
      "   100/   235: loss 0.011314\n",
      "   200/   235: loss 0.011422\n",
      "Dev Evaluation in Epoch  21\n",
      "[Epoch 21][ Dev] precision : 83.35, recall : 82.30, F1 : 82.82\n",
      "[new best model saved.]\n",
      "Epoch  22.....\n",
      "Start Training in Epoch  22\n",
      "   100/   235: loss 0.008710\n",
      "   200/   235: loss 0.010073\n",
      "Dev Evaluation in Epoch  22\n",
      "[Epoch 22][ Dev] precision : 83.10, recall : 82.77, F1 : 82.93\n",
      "[new best model saved.]\n",
      "Epoch  23.....\n",
      "Start Training in Epoch  23\n",
      "   100/   235: loss 0.007935\n",
      "   200/   235: loss 0.009507\n",
      "Dev Evaluation in Epoch  23\n",
      "[Epoch 23][ Dev] precision : 82.39, recall : 83.12, F1 : 82.75\n",
      "Epoch  24.....\n",
      "Start Training in Epoch  24\n",
      "   100/   235: loss 0.008959\n",
      "   200/   235: loss 0.009567\n",
      "Dev Evaluation in Epoch  24\n",
      "[Epoch 24][ Dev] precision : 83.94, recall : 83.73, F1 : 83.83\n",
      "[new best model saved.]\n",
      "Epoch  25.....\n",
      "Start Training in Epoch  25\n",
      "   100/   235: loss 0.007927\n",
      "   200/   235: loss 0.010107\n",
      "Dev Evaluation in Epoch  25\n",
      "[Epoch 25][ Dev] precision : 84.13, recall : 83.31, F1 : 83.71\n",
      "Epoch  26.....\n",
      "Start Training in Epoch  26\n",
      "   100/   235: loss 0.007076\n",
      "   200/   235: loss 0.008819\n",
      "Dev Evaluation in Epoch  26\n",
      "[Epoch 26][ Dev] precision : 83.70, recall : 83.54, F1 : 83.62\n",
      "Epoch  27.....\n",
      "Start Training in Epoch  27\n",
      "   100/   235: loss 0.006287\n",
      "   200/   235: loss 0.006936\n",
      "Dev Evaluation in Epoch  27\n",
      "[Epoch 27][ Dev] precision : 82.84, recall : 83.14, F1 : 82.99\n",
      "Epoch  28.....\n",
      "Start Training in Epoch  28\n",
      "   100/   235: loss 0.006996\n",
      "   200/   235: loss 0.007774\n",
      "Dev Evaluation in Epoch  28\n",
      "[Epoch 28][ Dev] precision : 83.53, recall : 83.02, F1 : 83.27\n",
      "Epoch  29.....\n",
      "Start Training in Epoch  29\n",
      "   100/   235: loss 0.006055\n",
      "   200/   235: loss 0.007373\n",
      "Dev Evaluation in Epoch  29\n",
      "[Epoch 29][ Dev] precision : 84.47, recall : 83.68, F1 : 84.07\n",
      "[new best model saved.]\n",
      "Epoch  30.....\n",
      "Start Training in Epoch  30\n",
      "   100/   235: loss 0.006223\n",
      "   200/   235: loss 0.006341\n",
      "Dev Evaluation in Epoch  30\n",
      "[Epoch 30][ Dev] precision : 83.92, recall : 82.99, F1 : 83.45\n",
      "Epoch  31.....\n",
      "Start Training in Epoch  31\n",
      "   100/   235: loss 0.004974\n",
      "   200/   235: loss 0.006660\n",
      "Dev Evaluation in Epoch  31\n",
      "[Epoch 31][ Dev] precision : 83.18, recall : 83.46, F1 : 83.32\n",
      "Epoch  32.....\n",
      "Start Training in Epoch  32\n",
      "   100/   235: loss 0.006097\n",
      "   200/   235: loss 0.004917\n",
      "Dev Evaluation in Epoch  32\n",
      "[Epoch 32][ Dev] precision : 84.01, recall : 83.71, F1 : 83.86\n",
      "Epoch  33.....\n",
      "Start Training in Epoch  33\n",
      "   100/   235: loss 0.005425\n",
      "   200/   235: loss 0.005937\n",
      "Dev Evaluation in Epoch  33\n",
      "[Epoch 33][ Dev] precision : 84.65, recall : 84.25, F1 : 84.45\n",
      "[new best model saved.]\n",
      "Epoch  34.....\n",
      "Start Training in Epoch  34\n",
      "   100/   235: loss 0.004561\n",
      "   200/   235: loss 0.005811\n",
      "Dev Evaluation in Epoch  34\n",
      "[Epoch 34][ Dev] precision : 84.05, recall : 83.63, F1 : 83.84\n",
      "Epoch  35.....\n",
      "Start Training in Epoch  35\n",
      "   100/   235: loss 0.005451\n",
      "   200/   235: loss 0.006801\n",
      "Dev Evaluation in Epoch  35\n",
      "[Epoch 35][ Dev] precision : 83.96, recall : 83.68, F1 : 83.82\n",
      "Epoch  36.....\n",
      "Start Training in Epoch  36\n",
      "   100/   235: loss 0.005659\n",
      "   200/   235: loss 0.005088\n",
      "Dev Evaluation in Epoch  36\n",
      "[Epoch 36][ Dev] precision : 83.97, recall : 83.94, F1 : 83.96\n",
      "Epoch  37.....\n",
      "Start Training in Epoch  37\n",
      "   100/   235: loss 0.005040\n",
      "   200/   235: loss 0.005745\n",
      "Dev Evaluation in Epoch  37\n",
      "[Epoch 37][ Dev] precision : 83.74, recall : 83.64, F1 : 83.69\n",
      "Epoch  38.....\n",
      "Start Training in Epoch  38\n",
      "   100/   235: loss 0.004992\n",
      "   200/   235: loss 0.004536\n",
      "Dev Evaluation in Epoch  38\n",
      "[Epoch 38][ Dev] precision : 83.81, recall : 83.81, F1 : 83.81\n",
      "Epoch  39.....\n",
      "Start Training in Epoch  39\n",
      "   100/   235: loss 0.004487\n",
      "   200/   235: loss 0.005155\n",
      "Dev Evaluation in Epoch  39\n",
      "[Epoch 39][ Dev] precision : 84.32, recall : 84.42, F1 : 84.37\n",
      "Epoch  40.....\n",
      "Start Training in Epoch  40\n",
      "   100/   235: loss 0.004181\n",
      "   200/   235: loss 0.004589\n",
      "Dev Evaluation in Epoch  40\n",
      "[Epoch 40][ Dev] precision : 83.66, recall : 83.74, F1 : 83.70\n",
      "Epoch  41.....\n",
      "Start Training in Epoch  41\n",
      "   100/   235: loss 0.004304\n",
      "   200/   235: loss 0.004506\n",
      "Dev Evaluation in Epoch  41\n",
      "[Epoch 41][ Dev] precision : 84.70, recall : 84.15, F1 : 84.42\n",
      "Epoch  42.....\n",
      "Start Training in Epoch  42\n",
      "   100/   235: loss 0.004037\n",
      "   200/   235: loss 0.004559\n",
      "Dev Evaluation in Epoch  42\n",
      "[Epoch 42][ Dev] precision : 84.56, recall : 83.89, F1 : 84.23\n",
      "Epoch  43.....\n",
      "Start Training in Epoch  43\n",
      "   100/   235: loss 0.004003\n",
      "   200/   235: loss 0.004401\n",
      "Dev Evaluation in Epoch  43\n",
      "[Epoch 43][ Dev] precision : 84.28, recall : 83.64, F1 : 83.96\n",
      "Epoch  44.....\n",
      "Start Training in Epoch  44\n",
      "   100/   235: loss 0.003603\n",
      "   200/   235: loss 0.003620\n",
      "Dev Evaluation in Epoch  44\n",
      "[Epoch 44][ Dev] precision : 83.79, recall : 84.15, F1 : 83.97\n",
      "Epoch  45.....\n",
      "Start Training in Epoch  45\n",
      "   100/   235: loss 0.003855\n",
      "   200/   235: loss 0.004084\n",
      "Dev Evaluation in Epoch  45\n",
      "[Epoch 45][ Dev] precision : 84.06, recall : 83.68, F1 : 83.87\n",
      "Epoch  46.....\n",
      "Start Training in Epoch  46\n",
      "   100/   235: loss 0.003651\n",
      "   200/   235: loss 0.004356\n",
      "Dev Evaluation in Epoch  46\n",
      "[Epoch 46][ Dev] precision : 84.66, recall : 83.98, F1 : 84.32\n",
      "Epoch  47.....\n",
      "Start Training in Epoch  47\n",
      "   100/   235: loss 0.004564\n",
      "   200/   235: loss 0.004304\n",
      "Dev Evaluation in Epoch  47\n",
      "[Epoch 47][ Dev] precision : 84.87, recall : 84.67, F1 : 84.77\n",
      "[new best model saved.]\n",
      "Epoch  48.....\n",
      "Start Training in Epoch  48\n",
      "   100/   235: loss 0.003431\n",
      "   200/   235: loss 0.003604\n",
      "Dev Evaluation in Epoch  48\n",
      "[Epoch 48][ Dev] precision : 83.97, recall : 83.83, F1 : 83.90\n",
      "Epoch  49.....\n",
      "Start Training in Epoch  49\n",
      "   100/   235: loss 0.003575\n",
      "   200/   235: loss 0.003651\n",
      "Dev Evaluation in Epoch  49\n",
      "[Epoch 49][ Dev] precision : 84.83, recall : 84.42, F1 : 84.62\n",
      "Epoch  50.....\n",
      "Start Training in Epoch  50\n",
      "   100/   235: loss 0.003160\n",
      "   200/   235: loss 0.002970\n",
      "Dev Evaluation in Epoch  50\n",
      "[Epoch 50][ Dev] precision : 84.66, recall : 84.53, F1 : 84.60\n",
      "Epoch  51.....\n",
      "Start Training in Epoch  51\n",
      "   100/   235: loss 0.003746\n",
      "   200/   235: loss 0.003322\n",
      "Dev Evaluation in Epoch  51\n",
      "[Epoch 51][ Dev] precision : 84.26, recall : 83.15, F1 : 83.70\n",
      "Epoch  52.....\n",
      "Start Training in Epoch  52\n",
      "   100/   235: loss 0.003271\n",
      "   200/   235: loss 0.003330\n",
      "Dev Evaluation in Epoch  52\n",
      "[Epoch 52][ Dev] precision : 84.95, recall : 84.52, F1 : 84.73\n",
      "Epoch  53.....\n",
      "Start Training in Epoch  53\n",
      "   100/   235: loss 0.002434\n",
      "   200/   235: loss 0.003881\n",
      "Dev Evaluation in Epoch  53\n",
      "[Epoch 53][ Dev] precision : 85.05, recall : 84.53, F1 : 84.79\n",
      "[new best model saved.]\n",
      "Epoch  54.....\n",
      "Start Training in Epoch  54\n",
      "   100/   235: loss 0.003209\n",
      "   200/   235: loss 0.003253\n",
      "Dev Evaluation in Epoch  54\n",
      "[Epoch 54][ Dev] precision : 84.32, recall : 83.89, F1 : 84.11\n",
      "Epoch  55.....\n",
      "Start Training in Epoch  55\n",
      "   100/   235: loss 0.002875\n",
      "   200/   235: loss 0.002778\n",
      "Dev Evaluation in Epoch  55\n",
      "[Epoch 55][ Dev] precision : 84.61, recall : 84.45, F1 : 84.53\n",
      "Epoch  56.....\n",
      "Start Training in Epoch  56\n",
      "   100/   235: loss 0.002446\n",
      "   200/   235: loss 0.003771\n",
      "Dev Evaluation in Epoch  56\n",
      "[Epoch 56][ Dev] precision : 85.12, recall : 84.03, F1 : 84.57\n",
      "Epoch  57.....\n",
      "Start Training in Epoch  57\n",
      "   100/   235: loss 0.003396\n",
      "   200/   235: loss 0.003701\n",
      "Dev Evaluation in Epoch  57\n",
      "[Epoch 57][ Dev] precision : 84.68, recall : 84.00, F1 : 84.34\n",
      "Epoch  58.....\n",
      "Start Training in Epoch  58\n",
      "   100/   235: loss 0.003229\n",
      "   200/   235: loss 0.003732\n",
      "Dev Evaluation in Epoch  58\n",
      "[Epoch 58][ Dev] precision : 84.92, recall : 84.43, F1 : 84.68\n",
      "Epoch  59.....\n",
      "Start Training in Epoch  59\n",
      "   100/   235: loss 0.002854\n",
      "   200/   235: loss 0.002778\n",
      "Dev Evaluation in Epoch  59\n",
      "[Epoch 59][ Dev] precision : 83.79, recall : 84.06, F1 : 83.93\n",
      "Epoch  60.....\n",
      "Start Training in Epoch  60\n",
      "   100/   235: loss 0.002437\n",
      "   200/   235: loss 0.002917\n",
      "Dev Evaluation in Epoch  60\n",
      "[Epoch 60][ Dev] precision : 85.07, recall : 84.60, F1 : 84.84\n",
      "[new best model saved.]\n"
     ]
    }
   ],
   "source": [
    "train(epochs=epochs,\n",
    "      batch_size=batch_size,\n",
    "      word_dim=word_dim,\n",
    "      pos_dim=pos_dim,\n",
    "      hidden_size=hidden_size,\n",
    "      rnn_layers=rnn_layers,\n",
    "      bidirectional=bidirectional,\n",
    "      use_pretrained=use_pretrained,\n",
    "      use_crf=False,\n",
    "      dropout_rate=dropout_rate,\n",
    "      evaluate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "auburn-thriller",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1.....\n",
      "Start Training in Epoch   1\n",
      "   100/   235: loss 524.053711\n",
      "   200/   235: loss 301.125244\n",
      "Dev Evaluation in Epoch   1\n",
      "[Epoch 1][ Dev] precision : 49.57, recall : 46.20, F1 : 47.82\n",
      "[new best model saved.]\n",
      "Epoch   2.....\n",
      "Start Training in Epoch   2\n",
      "   100/   235: loss 226.138290\n",
      "   200/   235: loss 207.594955\n",
      "Dev Evaluation in Epoch   2\n",
      "[Epoch 2][ Dev] precision : 63.69, recall : 61.41, F1 : 62.53\n",
      "[new best model saved.]\n",
      "Epoch   3.....\n",
      "Start Training in Epoch   3\n",
      "   100/   235: loss 158.671906\n",
      "   200/   235: loss 158.365036\n",
      "Dev Evaluation in Epoch   3\n",
      "[Epoch 3][ Dev] precision : 71.25, recall : 68.98, F1 : 70.10\n",
      "[new best model saved.]\n",
      "Epoch   4.....\n",
      "Start Training in Epoch   4\n",
      "   100/   235: loss 120.061691\n",
      "   200/   235: loss 124.809647\n",
      "Dev Evaluation in Epoch   4\n",
      "[Epoch 4][ Dev] precision : 75.44, recall : 73.16, F1 : 74.28\n",
      "[new best model saved.]\n",
      "Epoch   5.....\n",
      "Start Training in Epoch   5\n",
      "   100/   235: loss 93.070221\n",
      "   200/   235: loss 100.705505\n",
      "Dev Evaluation in Epoch   5\n",
      "[Epoch 5][ Dev] precision : 77.70, recall : 76.24, F1 : 76.96\n",
      "[new best model saved.]\n",
      "Epoch   6.....\n",
      "Start Training in Epoch   6\n",
      "   100/   235: loss 74.047287\n",
      "   200/   235: loss 80.812950\n",
      "Dev Evaluation in Epoch   6\n",
      "[Epoch 6][ Dev] precision : 78.92, recall : 77.94, F1 : 78.43\n",
      "[new best model saved.]\n",
      "Epoch   7.....\n",
      "Start Training in Epoch   7\n",
      "   100/   235: loss 59.095051\n",
      "   200/   235: loss 64.444695\n",
      "Dev Evaluation in Epoch   7\n",
      "[Epoch 7][ Dev] precision : 80.58, recall : 78.64, F1 : 79.60\n",
      "[new best model saved.]\n",
      "Epoch   8.....\n",
      "Start Training in Epoch   8\n",
      "   100/   235: loss 47.217144\n",
      "   200/   235: loss 50.418144\n",
      "Dev Evaluation in Epoch   8\n",
      "[Epoch 8][ Dev] precision : 81.77, recall : 79.59, F1 : 80.67\n",
      "[new best model saved.]\n",
      "Epoch   9.....\n",
      "Start Training in Epoch   9\n",
      "   100/   235: loss 39.036884\n",
      "   200/   235: loss 40.823536\n",
      "Dev Evaluation in Epoch   9\n",
      "[Epoch 9][ Dev] precision : 82.26, recall : 79.52, F1 : 80.87\n",
      "[new best model saved.]\n",
      "Epoch  10.....\n",
      "Start Training in Epoch  10\n",
      "   100/   235: loss 33.271393\n",
      "   200/   235: loss 34.293892\n",
      "Dev Evaluation in Epoch  10\n",
      "[Epoch 10][ Dev] precision : 82.96, recall : 81.47, F1 : 82.21\n",
      "[new best model saved.]\n",
      "Epoch  11.....\n",
      "Start Training in Epoch  11\n",
      "   100/   235: loss 26.258732\n",
      "   200/   235: loss 29.287146\n",
      "Dev Evaluation in Epoch  11\n",
      "[Epoch 11][ Dev] precision : 83.95, recall : 82.30, F1 : 83.11\n",
      "[new best model saved.]\n",
      "Epoch  12.....\n",
      "Start Training in Epoch  12\n",
      "   100/   235: loss 23.044983\n",
      "   200/   235: loss 22.907482\n",
      "Dev Evaluation in Epoch  12\n",
      "[Epoch 12][ Dev] precision : 84.07, recall : 82.35, F1 : 83.20\n",
      "[new best model saved.]\n",
      "Epoch  13.....\n",
      "Start Training in Epoch  13\n",
      "   100/   235: loss 18.690825\n",
      "   200/   235: loss 20.451159\n",
      "Dev Evaluation in Epoch  13\n",
      "[Epoch 13][ Dev] precision : 84.33, recall : 82.99, F1 : 83.65\n",
      "[new best model saved.]\n",
      "Epoch  14.....\n",
      "Start Training in Epoch  14\n",
      "   100/   235: loss 15.715375\n",
      "   200/   235: loss 17.701698\n",
      "Dev Evaluation in Epoch  14\n",
      "[Epoch 14][ Dev] precision : 84.83, recall : 83.41, F1 : 84.11\n",
      "[new best model saved.]\n",
      "Epoch  15.....\n",
      "Start Training in Epoch  15\n",
      "   100/   235: loss 13.603959\n",
      "   200/   235: loss 16.278482\n",
      "Dev Evaluation in Epoch  15\n",
      "[Epoch 15][ Dev] precision : 84.59, recall : 83.31, F1 : 83.94\n",
      "Epoch  16.....\n",
      "Start Training in Epoch  16\n",
      "   100/   235: loss 12.770282\n",
      "   200/   235: loss 13.301466\n",
      "Dev Evaluation in Epoch  16\n",
      "[Epoch 16][ Dev] precision : 84.39, recall : 83.04, F1 : 83.71\n",
      "Epoch  17.....\n",
      "Start Training in Epoch  17\n",
      "   100/   235: loss 11.295092\n",
      "   200/   235: loss 12.099293\n",
      "Dev Evaluation in Epoch  17\n",
      "[Epoch 17][ Dev] precision : 85.36, recall : 84.50, F1 : 84.93\n",
      "[new best model saved.]\n",
      "Epoch  18.....\n",
      "Start Training in Epoch  18\n",
      "   100/   235: loss 9.868123\n",
      "   200/   235: loss 10.572628\n",
      "Dev Evaluation in Epoch  18\n",
      "[Epoch 18][ Dev] precision : 84.55, recall : 82.51, F1 : 83.52\n",
      "Epoch  19.....\n",
      "Start Training in Epoch  19\n",
      "   100/   235: loss 9.031359\n",
      "   200/   235: loss 10.026896\n",
      "Dev Evaluation in Epoch  19\n",
      "[Epoch 19][ Dev] precision : 84.62, recall : 83.09, F1 : 83.85\n",
      "Epoch  20.....\n",
      "Start Training in Epoch  20\n",
      "   100/   235: loss 8.522433\n",
      "   200/   235: loss 8.827560\n",
      "Dev Evaluation in Epoch  20\n",
      "[Epoch 20][ Dev] precision : 84.03, recall : 82.63, F1 : 83.33\n",
      "Epoch  21.....\n",
      "Start Training in Epoch  21\n",
      "   100/   235: loss 7.680993\n",
      "   200/   235: loss 8.597764\n",
      "Dev Evaluation in Epoch  21\n",
      "[Epoch 21][ Dev] precision : 84.70, recall : 83.69, F1 : 84.20\n",
      "Epoch  22.....\n",
      "Start Training in Epoch  22\n",
      "   100/   235: loss 7.227112\n",
      "   200/   235: loss 7.853090\n",
      "Dev Evaluation in Epoch  22\n",
      "[Epoch 22][ Dev] precision : 86.25, recall : 83.79, F1 : 85.00\n",
      "[new best model saved.]\n",
      "Epoch  23.....\n",
      "Start Training in Epoch  23\n",
      "   100/   235: loss 6.537020\n",
      "   200/   235: loss 7.298872\n",
      "Dev Evaluation in Epoch  23\n",
      "[Epoch 23][ Dev] precision : 85.83, recall : 83.83, F1 : 84.82\n",
      "Epoch  24.....\n",
      "Start Training in Epoch  24\n",
      "   100/   235: loss 6.246897\n",
      "   200/   235: loss 7.272045\n",
      "Dev Evaluation in Epoch  24\n",
      "[Epoch 24][ Dev] precision : 84.93, recall : 83.47, F1 : 84.20\n",
      "Epoch  25.....\n",
      "Start Training in Epoch  25\n",
      "   100/   235: loss 6.036691\n",
      "   200/   235: loss 6.628270\n",
      "Dev Evaluation in Epoch  25\n",
      "[Epoch 25][ Dev] precision : 85.62, recall : 84.20, F1 : 84.90\n",
      "Epoch  26.....\n",
      "Start Training in Epoch  26\n",
      "   100/   235: loss 5.362319\n",
      "   200/   235: loss 5.838027\n",
      "Dev Evaluation in Epoch  26\n",
      "[Epoch 26][ Dev] precision : 85.15, recall : 83.37, F1 : 84.25\n",
      "Epoch  27.....\n",
      "Start Training in Epoch  27\n",
      "   100/   235: loss 4.874712\n",
      "   200/   235: loss 6.146864\n",
      "Dev Evaluation in Epoch  27\n",
      "[Epoch 27][ Dev] precision : 85.29, recall : 82.95, F1 : 84.11\n",
      "Epoch  28.....\n",
      "Start Training in Epoch  28\n",
      "   100/   235: loss 5.112921\n",
      "   200/   235: loss 5.784836\n",
      "Dev Evaluation in Epoch  28\n",
      "[Epoch 28][ Dev] precision : 84.84, recall : 82.95, F1 : 83.88\n",
      "Epoch  29.....\n",
      "Start Training in Epoch  29\n",
      "   100/   235: loss 5.461921\n",
      "   200/   235: loss 5.792495\n",
      "Dev Evaluation in Epoch  29\n",
      "[Epoch 29][ Dev] precision : 86.20, recall : 83.88, F1 : 85.02\n",
      "[new best model saved.]\n",
      "Epoch  30.....\n",
      "Start Training in Epoch  30\n",
      "   100/   235: loss 5.039468\n",
      "   200/   235: loss 4.848170\n",
      "Dev Evaluation in Epoch  30\n",
      "[Epoch 30][ Dev] precision : 86.56, recall : 84.99, F1 : 85.77\n",
      "[new best model saved.]\n",
      "Epoch  31.....\n",
      "Start Training in Epoch  31\n",
      "   100/   235: loss 4.567504\n",
      "   200/   235: loss 5.776468\n",
      "Dev Evaluation in Epoch  31\n",
      "[Epoch 31][ Dev] precision : 86.82, recall : 84.94, F1 : 85.87\n",
      "[new best model saved.]\n",
      "Epoch  32.....\n",
      "Start Training in Epoch  32\n",
      "   100/   235: loss 4.048775\n",
      "   200/   235: loss 4.640547\n",
      "Dev Evaluation in Epoch  32\n",
      "[Epoch 32][ Dev] precision : 86.92, recall : 84.63, F1 : 85.76\n",
      "Epoch  33.....\n",
      "Start Training in Epoch  33\n",
      "   100/   235: loss 4.117214\n",
      "   200/   235: loss 4.483166\n",
      "Dev Evaluation in Epoch  33\n",
      "[Epoch 33][ Dev] precision : 85.60, recall : 84.45, F1 : 85.02\n",
      "Epoch  34.....\n",
      "Start Training in Epoch  34\n",
      "   100/   235: loss 3.877572\n",
      "   200/   235: loss 4.845168\n",
      "Dev Evaluation in Epoch  34\n",
      "[Epoch 34][ Dev] precision : 85.73, recall : 84.03, F1 : 84.87\n",
      "Epoch  35.....\n",
      "Start Training in Epoch  35\n",
      "   100/   235: loss 4.332784\n",
      "   200/   235: loss 4.555656\n",
      "Dev Evaluation in Epoch  35\n",
      "[Epoch 35][ Dev] precision : 86.28, recall : 84.35, F1 : 85.30\n",
      "Epoch  36.....\n",
      "Start Training in Epoch  36\n",
      "   100/   235: loss 3.714174\n",
      "   200/   235: loss 4.984934\n",
      "Dev Evaluation in Epoch  36\n",
      "[Epoch 36][ Dev] precision : 85.55, recall : 84.21, F1 : 84.88\n",
      "Epoch  37.....\n",
      "Start Training in Epoch  37\n",
      "   100/   235: loss 4.331629\n",
      "   200/   235: loss 3.925403\n",
      "Dev Evaluation in Epoch  37\n",
      "[Epoch 37][ Dev] precision : 85.92, recall : 84.08, F1 : 84.99\n",
      "Epoch  38.....\n",
      "Start Training in Epoch  38\n",
      "   100/   235: loss 3.347631\n",
      "   200/   235: loss 4.000854\n",
      "Dev Evaluation in Epoch  38\n",
      "[Epoch 38][ Dev] precision : 86.63, recall : 84.72, F1 : 85.66\n",
      "Epoch  39.....\n",
      "Start Training in Epoch  39\n",
      "   100/   235: loss 3.268885\n",
      "   200/   235: loss 4.327703\n",
      "Dev Evaluation in Epoch  39\n",
      "[Epoch 39][ Dev] precision : 86.26, recall : 85.02, F1 : 85.63\n",
      "Epoch  40.....\n",
      "Start Training in Epoch  40\n",
      "   100/   235: loss 3.255069\n",
      "   200/   235: loss 3.578357\n",
      "Dev Evaluation in Epoch  40\n",
      "[Epoch 40][ Dev] precision : 86.17, recall : 84.21, F1 : 85.18\n",
      "Epoch  41.....\n",
      "Start Training in Epoch  41\n",
      "   100/   235: loss 2.786611\n",
      "   200/   235: loss 3.562880\n",
      "Dev Evaluation in Epoch  41\n",
      "[Epoch 41][ Dev] precision : 87.53, recall : 85.31, F1 : 86.41\n",
      "[new best model saved.]\n",
      "Epoch  42.....\n",
      "Start Training in Epoch  42\n",
      "   100/   235: loss 3.326881\n",
      "   200/   235: loss 3.381723\n",
      "Dev Evaluation in Epoch  42\n",
      "[Epoch 42][ Dev] precision : 87.10, recall : 85.19, F1 : 86.13\n",
      "Epoch  43.....\n",
      "Start Training in Epoch  43\n",
      "   100/   235: loss 2.714606\n",
      "   200/   235: loss 2.839172\n",
      "Dev Evaluation in Epoch  43\n",
      "[Epoch 43][ Dev] precision : 86.53, recall : 84.69, F1 : 85.60\n",
      "Epoch  44.....\n",
      "Start Training in Epoch  44\n",
      "   100/   235: loss 2.552776\n",
      "   200/   235: loss 2.985770\n",
      "Dev Evaluation in Epoch  44\n",
      "[Epoch 44][ Dev] precision : 86.54, recall : 85.06, F1 : 85.79\n",
      "Epoch  45.....\n",
      "Start Training in Epoch  45\n",
      "   100/   235: loss 2.682635\n",
      "   200/   235: loss 3.348426\n",
      "Dev Evaluation in Epoch  45\n",
      "[Epoch 45][ Dev] precision : 86.17, recall : 85.01, F1 : 85.58\n",
      "Epoch  46.....\n",
      "Start Training in Epoch  46\n",
      "   100/   235: loss 2.784189\n",
      "   200/   235: loss 2.963467\n",
      "Dev Evaluation in Epoch  46\n",
      "[Epoch 46][ Dev] precision : 86.89, recall : 85.34, F1 : 86.11\n",
      "Epoch  47.....\n",
      "Start Training in Epoch  47\n",
      "   100/   235: loss 2.947397\n",
      "   200/   235: loss 2.882358\n",
      "Dev Evaluation in Epoch  47\n",
      "[Epoch 47][ Dev] precision : 87.02, recall : 84.60, F1 : 85.79\n",
      "Epoch  48.....\n",
      "Start Training in Epoch  48\n",
      "   100/   235: loss 2.820036\n",
      "   200/   235: loss 2.884306\n",
      "Dev Evaluation in Epoch  48\n",
      "[Epoch 48][ Dev] precision : 86.71, recall : 84.87, F1 : 85.78\n",
      "Epoch  49.....\n",
      "Start Training in Epoch  49\n",
      "   100/   235: loss 2.552496\n",
      "   200/   235: loss 3.092968\n",
      "Dev Evaluation in Epoch  49\n",
      "[Epoch 49][ Dev] precision : 87.00, recall : 85.29, F1 : 86.14\n",
      "Epoch  50.....\n",
      "Start Training in Epoch  50\n",
      "   100/   235: loss 2.358542\n",
      "   200/   235: loss 2.897730\n",
      "Dev Evaluation in Epoch  50\n",
      "[Epoch 50][ Dev] precision : 86.31, recall : 84.37, F1 : 85.33\n",
      "Epoch  51.....\n",
      "Start Training in Epoch  51\n",
      "   100/   235: loss 2.653596\n",
      "   200/   235: loss 2.861499\n",
      "Dev Evaluation in Epoch  51\n",
      "[Epoch 51][ Dev] precision : 87.08, recall : 84.70, F1 : 85.87\n",
      "Epoch  52.....\n",
      "Start Training in Epoch  52\n",
      "   100/   235: loss 2.700355\n",
      "   200/   235: loss 3.759151\n",
      "Dev Evaluation in Epoch  52\n",
      "[Epoch 52][ Dev] precision : 85.53, recall : 83.66, F1 : 84.58\n",
      "Epoch  53.....\n",
      "Start Training in Epoch  53\n",
      "   100/   235: loss 2.491056\n",
      "   200/   235: loss 2.876697\n",
      "Dev Evaluation in Epoch  53\n",
      "[Epoch 53][ Dev] precision : 86.94, recall : 85.58, F1 : 86.25\n",
      "Epoch  54.....\n",
      "Start Training in Epoch  54\n",
      "   100/   235: loss 2.412377\n",
      "   200/   235: loss 2.648833\n",
      "Dev Evaluation in Epoch  54\n",
      "[Epoch 54][ Dev] precision : 86.53, recall : 85.31, F1 : 85.92\n",
      "Epoch  55.....\n",
      "Start Training in Epoch  55\n",
      "   100/   235: loss 2.331723\n",
      "   200/   235: loss 2.697100\n",
      "Dev Evaluation in Epoch  55\n",
      "[Epoch 55][ Dev] precision : 86.63, recall : 85.59, F1 : 86.11\n",
      "Epoch  56.....\n",
      "Start Training in Epoch  56\n",
      "   100/   235: loss 1.846811\n",
      "   200/   235: loss 2.562968\n",
      "Dev Evaluation in Epoch  56\n",
      "[Epoch 56][ Dev] precision : 85.86, recall : 84.48, F1 : 85.16\n",
      "Epoch  57.....\n",
      "Start Training in Epoch  57\n",
      "   100/   235: loss 1.852287\n",
      "   200/   235: loss 2.972078\n",
      "Dev Evaluation in Epoch  57\n",
      "[Epoch 57][ Dev] precision : 87.15, recall : 85.85, F1 : 86.49\n",
      "[new best model saved.]\n",
      "Epoch  58.....\n",
      "Start Training in Epoch  58\n",
      "   100/   235: loss 2.026272\n",
      "   200/   235: loss 2.768512\n",
      "Dev Evaluation in Epoch  58\n",
      "[Epoch 58][ Dev] precision : 86.80, recall : 85.68, F1 : 86.24\n",
      "Epoch  59.....\n",
      "Start Training in Epoch  59\n",
      "   100/   235: loss 1.985571\n",
      "   200/   235: loss 2.083910\n",
      "Dev Evaluation in Epoch  59\n",
      "[Epoch 59][ Dev] precision : 85.80, recall : 84.42, F1 : 85.10\n",
      "Epoch  60.....\n",
      "Start Training in Epoch  60\n",
      "   100/   235: loss 2.151832\n",
      "   200/   235: loss 2.688035\n",
      "Dev Evaluation in Epoch  60\n",
      "[Epoch 60][ Dev] precision : 84.87, recall : 83.34, F1 : 84.10\n"
     ]
    }
   ],
   "source": [
    "train(epochs=epochs,\n",
    "      batch_size=batch_size,\n",
    "      word_dim=word_dim,\n",
    "      pos_dim=pos_dim,\n",
    "      hidden_size=hidden_size,\n",
    "      rnn_layers=rnn_layers,\n",
    "      bidirectional=bidirectional,\n",
    "      use_pretrained=use_pretrained,\n",
    "      use_crf=True,\n",
    "      dropout_rate=dropout_rate,\n",
    "      evaluate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
