{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "settled-wales",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "criminal-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from dataload import lang, localdata\n",
    "from tagger.bilstmcrf import BiLSTMCRF\n",
    "from etc.customUtil import showGraph, showParallel\n",
    "from etc import defaultsetting as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "universal-bermuda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "victorian-hebrew",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21591\n",
      "82\n",
      "46\n",
      "54\n",
      "78\n",
      "4\n",
      "78\n",
      "936\n",
      "2012\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "tag_PAD = ds.TOKKEN_PAD_IDX\n",
    "tag_UNK = ds.TOKKEN_UNK_IDX\n",
    "\n",
    "datasets, engdict, posdict = localdata.load_eng_pos(device) # , charmode=True)\n",
    "num_words = engdict.n_words\n",
    "num_chars = engdict.n_chars\n",
    "num_poss = posdict.n_words\n",
    "print(num_words)\n",
    "print(num_chars)\n",
    "print(num_poss)\n",
    "# print(MAX_LENGTH)\n",
    "print(engdict.max_len_char)\n",
    "print(engdict.max_len_word)\n",
    "print(posdict.max_len_char)\n",
    "print(posdict.max_len_word)\n",
    "\n",
    "print(len(datasets['dev'].y_data))\n",
    "print(len(datasets['test'].y_data))\n",
    "print(len(datasets['train'].y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "inside-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iteration(samples, optimizer):\n",
    "    x_train, y_train = samples\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss = model(x_train, y_train)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "periodic-cooking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch(model, optimizer, dataloader):\n",
    "    model.train()\n",
    "    list_loss = []\n",
    "    for batch_idx, samples in enumerate(dataloader):\n",
    "        loss = iteration(samples, optimizer)\n",
    "        list_loss.append(loss.item())\n",
    "    return list_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "persistent-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    for batch_idx, samples in enumerate(dataloader):\n",
    "        x_train, y_train = samples\n",
    "\n",
    "        loss = model(x_train, y_train, lossmode=True)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # if batch_idx % 100 == 0:\n",
    "            # print(batch_idx, loss.item())\n",
    "            \n",
    "    # print(batch_idx, loss.item())\n",
    "    return total_loss / (batch_idx+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "selected-shirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(model, dataset, batch_size):\n",
    "    model.eval()\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    num_samples = len(dataset)\n",
    "    cnt_corr_samples = 0\n",
    "    total_words = 0\n",
    "    cnt_corr_words = 0\n",
    "    c = posdict.n_words\n",
    "    table = torch.zeros(c,c)\n",
    "    \n",
    "    for batch_idx, samples in enumerate(dataloader):\n",
    "        x_train, y_train = samples\n",
    "        \n",
    "        tagged = model(x_train, lossmode=False)\n",
    "        tagged = torch.tensor(tagged, device=device)\n",
    "        \n",
    "        for i in range(x_train.size(0)):\n",
    "            l = y_train[i].tolist()\n",
    "            if tag_PAD in l:\n",
    "                seq_len = l.index(tag_PAD)\n",
    "            else:\n",
    "                seq_len = len(l)\n",
    "            \n",
    "            _y = y_train[i,:seq_len]\n",
    "            _p = tagged[i,:seq_len]\n",
    "            d = _p!=_y\n",
    "            cnt_wrong = _p[d].size()[0]\n",
    "            \n",
    "            # score1_acc_sample\n",
    "            if cnt_wrong == 0:\n",
    "                cnt_corr_samples +=1\n",
    "                \n",
    "            # score2_acc_word\n",
    "            total_words += seq_len\n",
    "            cnt_corr_words += seq_len - cnt_wrong\n",
    "            \n",
    "            # score3_f1\n",
    "            for j in range(seq_len):\n",
    "                table[_y[j],_p[j]] += 1\n",
    "\n",
    "    tp = torch.tensor([table[i,i] for i in range(c)])[2:]\n",
    "    d0sum = table[2:,2:].sum(dim=0)\n",
    "    d1sum = table[2:,2:].sum(dim=1)\n",
    "    allsum = d1sum.sum()\n",
    "    \n",
    "    pr = tp / d0sum\n",
    "    temp = pr != pr\n",
    "    pr[temp] = 0\n",
    "    \n",
    "    re = tp / d1sum\n",
    "    temp = re != re\n",
    "    re[temp] = 0\n",
    "    \n",
    "    f1 = 2 * pr * re / (pr + re)\n",
    "    temp = f1 != f1\n",
    "    f1[temp] = 0\n",
    "    \n",
    "    avg_f1 = (f1 * d1sum).sum() / allsum\n",
    "  \n",
    "    return (cnt_corr_samples / num_samples,\n",
    "            cnt_corr_words / total_words,\n",
    "            avg_f1.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "oriented-mileage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_losses_scores(model, optimizer, datasets, batch_size, num_epoch):\n",
    "\n",
    "    dict_losses={'train': [],\n",
    "                 'dev': [],\n",
    "                 'test': []}\n",
    "    \n",
    "    dict_scores={'train': [[],[],[]],\n",
    "                 'dev': [[],[],[]],\n",
    "                 'test': [[],[],[]]}\n",
    "    best_dev_f1 = 0.0\n",
    "    for epoch_i in range(1,num_epoch+1):\n",
    "        dataloader = DataLoader(datasets['train'], batch_size=batch_size, shuffle=True)\n",
    "        dataloader_dev = DataLoader(datasets['dev'], batch_size=len(datasets['dev']), shuffle=True)\n",
    "        dataloader_test = DataLoader(datasets['test'], batch_size=len(datasets['test']), shuffle=True)\n",
    "        print(f'\\r{epoch_i}', end='')\n",
    "        temp = epoch(model, optimizer, dataloader)\n",
    "        dict_losses['train'].extend(temp)\n",
    "        dict_losses['dev'].append(evaluate(model, dataloader_dev))\n",
    "        dict_losses['test'].append(evaluate(model, dataloader_test))\n",
    "\n",
    "        s_train = scores(model, datasets['train'], 100)\n",
    "        s_dev = scores(model, datasets['dev'], 100)\n",
    "        s_test = scores(model, datasets['test'], 100)\n",
    "        \n",
    "        dict_scores['train'][0].append(s_train[0])\n",
    "        dict_scores['train'][1].append(s_train[1])\n",
    "        dict_scores['train'][2].append(s_train[2])\n",
    "        dict_scores['dev'][0].append(s_dev[0])\n",
    "        dict_scores['dev'][1].append(s_dev[1])\n",
    "        dict_scores['dev'][2].append(s_dev[2])\n",
    "        dict_scores['test'][0].append(s_test[0])\n",
    "        dict_scores['test'][1].append(s_test[1])\n",
    "        dict_scores['test'][2].append(s_test[2])\n",
    "        \n",
    "        if s_dev[2] > best_dev_f1:\n",
    "            print(f' epoch Dev F1 score: {best_dev_f1:.6} -> {s_dev[2]:.6}')\n",
    "            best_dev_f1 = s_dev[2]\n",
    "            torch.save(model, 'best_bilstm_crf_pos.pt')\n",
    "    print()\n",
    "    return dict_losses, dict_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "amazing-mechanics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tagging(model, input_seq):\n",
    "    model.eval()\n",
    "    o = model(input_seq, lossmode=False)\n",
    "#     print(o)\n",
    "#     __tagged, tagged = torch.max(o, dim=-1)\n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "impaired-closer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc(model, input_seq, target_seq=None):\n",
    "    input_list = engdict.sentenceFromIndexes(input_seq.tolist())\n",
    "#     print(input_list)\n",
    "    # print(sentenceFromIndexes(posdict, target_seq.tolist()))\n",
    "    output_list = posdict.sentenceFromIndexes(pos_tagging(model, input_seq.unsqueeze(0))[0])\n",
    "    \n",
    "    target_list = None\n",
    "    if target_seq is not None:\n",
    "        target_list = posdict.sentenceFromIndexes(target_seq.tolist())\n",
    "\n",
    "#     print(output_list)\n",
    "    showParallel(input_list, output_list, target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "excessive-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "size_hidden = 50\n",
    "num_layers = 1\n",
    "size_out = num_poss\n",
    "size_batch = 100\n",
    "# criterion  = nn.CrossEntropyLoss().to(device)\n",
    "# criterion  = nn.CrossEntropyLoss(ignore_index=tag_PAD).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "german-transfer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 epoch Dev F1 score: 0.0 -> 0.896226\n",
      "2 epoch Dev F1 score: 0.896226 -> 0.93751\n",
      "3 epoch Dev F1 score: 0.93751 -> 0.94724\n",
      "4 epoch Dev F1 score: 0.94724 -> 0.952517\n",
      "5 epoch Dev F1 score: 0.952517 -> 0.953544\n",
      "6 epoch Dev F1 score: 0.953544 -> 0.954454\n",
      "7 epoch Dev F1 score: 0.954454 -> 0.954604\n",
      "10 epoch Dev F1 score: 0.954604 -> 0.955441\n",
      "16 epoch Dev F1 score: 0.955441 -> 0.955839\n",
      "17 epoch Dev F1 score: 0.955839 -> 0.956117\n",
      "23"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-3bb93569c209>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnum_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdict_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_losses_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'\\t{time.time()-st:5}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-cefaabb38370>\u001b[0m in \u001b[0;36mtrain_losses_scores\u001b[1;34m(model, optimizer, datasets, batch_size, num_epoch)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mdict_losses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloader_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0ms_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0ms_dev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dev'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0ms_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-e2446f0fc166>\u001b[0m in \u001b[0;36mscores\u001b[1;34m(model, dataset, batch_size)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mtagged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlossmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mtagged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtagged\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\torchenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\SSD_Storage\\Repository\\Repo_Python\\BiLSTM_Tagging\\tagger\\bilstmcrf.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_seq, target_seq, lossmode)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;31m# print('e')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\torchenv\\lib\\site-packages\\torchcrf\\__init__.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, emissions, mask)\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_viterbi_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memissions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m     def _validate(\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\torchenv\\lib\\site-packages\\torchcrf\\__init__.py\u001b[0m in \u001b[0;36m_viterbi_decode\u001b[1;34m(self, emissions, mask)\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mhist\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mseq_ends\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m                 \u001b[0mbest_last_tag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbest_tags\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                 \u001b[0mbest_tags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_last_tag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[1;31m# Reverse the order because we start from the last timestep\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = BiLSTMCRF(num_words, embedding_dim, size_hidden, size_out, num_layers, tag_PAD).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epoch = 60\n",
    "st = time.time()\n",
    "dict_losses, dict_scores = train_losses_scores(model, optimizer, datasets, size_batch, num_epoch)\n",
    "print(f'\\t{time.time()-st:5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-television",
   "metadata": {},
   "outputs": [],
   "source": [
    "showGraph(dict_losses, dict_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-mouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_type=1\n",
    "for i in range(len(dict_scores[\"train\"][score_type])):\n",
    "    print(f'{dict_scores[\"train\"][score_type][i]:<.5}   {dict_scores[\"dev\"][score_type][i]:<05.4}   {dict_scores[\"test\"][score_type][i]:.5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-kelly",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = datasets['test']\n",
    "for ii in range(len(testset)):\n",
    "    i = 0\n",
    "    input_seq = testset.x_data[i]\n",
    "    target_seq = testset.y_data[i]\n",
    "    calc(model, input_seq, target_seq)\n",
    "    break\n",
    "#     print(target_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-arena",
   "metadata": {},
   "outputs": [],
   "source": [
    "sen = 'I am your father .'\n",
    "in_sen = torch.tensor(engdict.indexesFromSentence(sen), device=device)\n",
    "\n",
    "sen2 = [4609,   25,   35,  116, 4610, 1562,   74,  115, 4611,   49, 4612, 1456,\n",
    "        4613,  224,  691,    6, 4614,   76,   30, 1742, 4615,  308,  107, 4614,\n",
    "         116, 4616, 4617,   17]\n",
    "in_sen2 = torch.tensor(sen2, device=device)\n",
    "\n",
    "calc(model, in_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-prior",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-hepatitis",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = torch.load('best_bilstm_crf_pos.pt')\n",
    "s_dev = scores(best_model, datasets['dev'], 100)\n",
    "s_test = scores(best_model, datasets['test'], 100)\n",
    "print(s_dev)\n",
    "print(s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-belle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
